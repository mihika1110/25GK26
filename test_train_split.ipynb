{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1708b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79962449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed time series dataset\n",
    "df = pd.read_csv(\"preprocess_data_timeseries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a3a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (38879, 70)\n",
      "Date range: 2019-01-01 00:00:00 to 2019-05-15 23:50:00\n",
      "\n",
      "Available features: 65\n",
      "Base features: 8\n",
      "Time features: 12\n",
      "Lag features: 45\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "OPTION 1: TRADITIONAL MODELS like Random Forest, XGBoost, Linear Regression\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Traditional Train/Test data saved.\n",
      "Train shape: (27215, 65), Test shape: (11664, 65)\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "OPTION 2: TIME SERIES MODELS\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Training period: 2019-01-01 00:00:00 to 2019-04-05 11:50:00\n",
      "Testing period: 2019-04-05 11:55:00 to 2019-05-15 23:50:00\n",
      "Time Series Train/Test data saved chronologically.\n",
      "Train shape: (27215, 70), Test shape: (11664, 70)\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "OPTION 3: BACKWARD COMPATIBILITY\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Backward compatible data saved.\n",
      "Train shape: (27215, 8), Test shape: (11664, 8)\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "DATA SPLITTING DONE!!\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "3 datasets created:\n",
      "1. train_traditional.csv/test_traditional.csv - All features + shuffle\n",
      "2. train_timeseries.csv/test_timeseries.csv - Time series chronological\n",
      "3. train_multi_output.csv/test_multi_output.csv - Original features (backward compatible)\n"
     ]
    }
   ],
   "source": [
    "# Convert Time to datetime and sort\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "df = df.sort_values('Time')\n",
    "\n",
    "print(f\"Loaded dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['Time'].min()} to {df['Time'].max()}\")\n",
    "\n",
    "# Define feature sets for different model types\n",
    "basic_features = ['Season', 'Day_of_the_week', 'DHI', 'DNI', 'GHI', 'Wind_speed', 'Humidity', 'Temperature']\n",
    "time_based_features = ['hour', 'day_of_week', 'month', 'weekend', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos','is_night', 'is_morning', 'is_afternoon', 'is_evening']\n",
    "lag_features = [column_name for column_name in df.columns if 'lag' in column_name or 'rolling' in column_name]\n",
    "\n",
    "# Combine all available features\n",
    "all_features = basic_features + time_based_features + lag_features\n",
    "available_features = [f for f in all_features if f in df.columns]\n",
    "\n",
    "print(f\"\\nAvailable features: {len(available_features)}\")\n",
    "print(f\"Base features: {len([f for f in basic_features if f in df.columns])}\")\n",
    "print(f\"Time features: {len([f for f in time_based_features if f in df.columns])}\")\n",
    "print(f\"Lag features: {len([f for f in lag_features if f in df.columns])}\")\n",
    "\n",
    "# Define targets\n",
    "targets = ['PV_production', 'Wind_production']\n",
    "\n",
    "# OPTION 1: Traditional Models (Random Forest, XGBoost, Linear Regression)\n",
    "print(\"\\n\" + \"~\"*50)\n",
    "print(\"OPTION 1: TRADITIONAL MODELS like Random Forest, XGBoost, Linear Regression\")\n",
    "print(\"~\"*50)\n",
    "\n",
    "X_traditional = df[available_features]\n",
    "y_traditional = df[targets]\n",
    "\n",
    "# Split with shuffle for traditional models\n",
    "X_train_all_features, X_test_all_features, y_train_all_features, y_test_all_features = train_test_split(\n",
    "    X_traditional, y_traditional, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Save traditional model data\n",
    "train_data_trad = pd.concat([X_train_all_features, y_train_all_features], axis=1)\n",
    "test_data_trad = pd.concat([X_test_all_features, y_test_all_features], axis=1)\n",
    "\n",
    "train_data_trad.to_csv(\"train_traditional.csv\", index=False)\n",
    "test_data_trad.to_csv(\"test_traditional.csv\", index=False)\n",
    "\n",
    "print(\"Traditional Train/Test data saved.\")\n",
    "print(f\"Train shape: {X_train_all_features.shape}, Test shape: {X_test_all_features.shape}\")\n",
    "\n",
    "# OPTION 2: Time Series Models (LSTM, CNN-LSTM) - Chronological Split\n",
    "print(\"\\n\" + \"~\"*50)\n",
    "print(\"OPTION 2: TIME SERIES MODELS\")\n",
    "print(\"~\"*50)\n",
    "\n",
    "def time_series_split(df, test_size=0.3):\n",
    "    split_idx = int(len(df) * (1 - test_size))\n",
    "    train = df.iloc[:split_idx]\n",
    "    test = df.iloc[split_idx:]\n",
    "    return train, test\n",
    "\n",
    "# Split chronologically (NO SHUFFLE)\n",
    "train_ts, test_ts = time_series_split(df)\n",
    "\n",
    "print(f\"Training period: {train_ts['Time'].min()} to {train_ts['Time'].max()}\")\n",
    "print(f\"Testing period: {test_ts['Time'].min()} to {test_ts['Time'].max()}\")\n",
    "\n",
    "# Save time series data\n",
    "train_ts.to_csv(\"train_timeseries.csv\", index=False)\n",
    "test_ts.to_csv(\"test_timeseries.csv\", index=False)\n",
    "\n",
    "print(\"Time Series Train/Test data saved chronologically.\")\n",
    "print(f\"Train shape: {train_ts.shape}, Test shape: {test_ts.shape}\")\n",
    "\n",
    "# OPTION 3: Backward Compatibility (Your original format)\n",
    "print(\"\\n\" + \"~\"*50)\n",
    "print(\"OPTION 3: BACKWARD COMPATIBILITY\")\n",
    "print(\"~\"*50)\n",
    "\n",
    "# Use only original features for backward compatibility\n",
    "x_basic_features = df[basic_features]\n",
    "y_basic_targets = df[targets]\n",
    "\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(x_basic_features, y_basic_targets, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "train_data_orig = pd.concat([X_train_orig, y_train_orig], axis=1)\n",
    "test_data_orig = pd.concat([X_test_orig, y_test_orig], axis=1)\n",
    "\n",
    "train_data_orig.to_csv(\"train_multi_output.csv\", index=False)\n",
    "test_data_orig.to_csv(\"test_multi_output.csv\", index=False)\n",
    "\n",
    "print(\"Backward compatible data saved.\")\n",
    "print(f\"Train shape: {X_train_orig.shape}, Test shape: {X_test_orig.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"~\"*60)\n",
    "print(\"DATA SPLITTING DONE!!\")\n",
    "print(\"~\"*60)\n",
    "print(\"3 datasets created:\")\n",
    "print(\"1. train_traditional.csv/test_traditional.csv - All features + shuffle\")\n",
    "print(\"2. train_timeseries.csv/test_timeseries.csv - Time series chronological\")\n",
    "print(\"3. train_multi_output.csv/test_multi_output.csv - Original features (backward compatible)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
